{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed70a480-3686-4522-acee-ae48079579d2",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">\n",
    "  <a href=\"https://uptrain.ai\">\n",
    "    <img width=\"300\" src=\"https://user-images.githubusercontent.com/108270398/214240695-4f958b76-c993-4ddd-8de6-8668f4d0da84.png\" alt=\"uptrain\">\n",
    "  </a>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c074abda-7ad0-4af1-a7b4-f5177213dae8",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Fine-tuning a Large-Language Model [WIP]</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f34304-dc81-4fd9-94dc-a7dfc371673a",
   "metadata": {},
   "source": [
    "### Install Required packages\n",
    "- [PyTorch](https://pytorch.org/get-started/locally/): Deep learning framework.\n",
    "- Hugging Face Transformers(https://huggingface.co/docs/transformers/installation): To use pretrained state-of-the-art models.\n",
    "- [Hugging Face Datasets](https://pypi.org/project/datasets/): Use public Hugging Face datasets\n",
    "- [IPywidgets](https://ipywidgets.readthedocs.io/en/stable/user_install.html): For interactive notebook widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52468837-a2f1-4531-bef5-b95276db6b82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: transformers[torch] in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.26.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (7.6.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: uptrain in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.0.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers[torch]) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers[torch]) (1.20.2)\n",
      "Requirement already satisfied: requests in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers[torch]) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers[torch]) (20.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers[torch]) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers[torch]) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers[torch]) (2022.10.31)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers[torch]) (0.12.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: xxhash in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (1.2.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: dill<0.3.7 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (5.5.5)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (7.22.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (5.0.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (8.0.1)\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from uptrain) (5.13.0)\n",
      "Requirement already satisfied: umap-learn>=0.5.3 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from uptrain) (0.5.3)\n",
      "Requirement already satisfied: pydantic>=1.9.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from uptrain) (1.10.5)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from uptrain) (1.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (3.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: pygments in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (2.8.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (49.2.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (3.0.18)\n",
      "Requirement already satisfied: decorator in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (4.7.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.0->transformers[torch]) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2.8.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 23.0 is available.\n",
      "You should consider upgrading via the 'c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from plotly>=5.0.0->uptrain) (8.2.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers[torch]) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers[torch]) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers[torch]) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=1.0.0->uptrain) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=1.0.0->uptrain) (2.1.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from umap-learn>=0.5.3->uptrain) (0.5.8)\n",
      "Requirement already satisfied: numba>=0.49 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from umap-learn>=0.5.3->uptrain) (0.56.4)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.17.3)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.1.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.0.7)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.10.1)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (22.0.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.10.0)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets) (300)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from numba>=0.49->umap-learn>=0.5.3->uptrain) (0.39.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.3.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.3)\n",
      "Requirement already satisfied: testpath in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: async-generator in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\kanchan kumar kaity\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers[torch] datasets ipywidgets nltk uptrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f61005f8-27ae-4a7a-a190-fe5f335821cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import json\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import uptrain\n",
    "import pandas as pd\n",
    "\n",
    "from model_constants import *\n",
    "from model_train import retrain_model\n",
    "from helper_funcs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3753482-afaf-4210-8a3e-d4fb8a325ce2",
   "metadata": {},
   "source": [
    "Define few cases to test our model performance before and after retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3c59113-37e7-4245-8dc5-3e3d03bcdad6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing_texts = [\n",
    "    \"Nike shoes are very [MASK].\" , \"Website is [MASK].\" , 'customer service is [MASK].' , 'store is [MASK].' , 'Price is [MASK].' , 'delivery is [MASK].' , 'design is [MASK].' , 'fitting is [MASK].'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d6e1263-e704-4de2-af99-507ea68125fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\KANCHAN KUMAR KAITY/.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\1c4513b2eedbda136f57676a34eea67aba266e5c\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\KANCHAN KUMAR KAITY/.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\1c4513b2eedbda136f57676a34eea67aba266e5c\\vocab.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\KANCHAN KUMAR KAITY/.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\1c4513b2eedbda136f57676a34eea67aba266e5c\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\KANCHAN KUMAR KAITY/.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\1c4513b2eedbda136f57676a34eea67aba266e5c\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\KANCHAN KUMAR KAITY/.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\1c4513b2eedbda136f57676a34eea67aba266e5c\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\KANCHAN KUMAR KAITY/.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\1c4513b2eedbda136f57676a34eea67aba266e5c\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\KANCHAN KUMAR KAITY/.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\1c4513b2eedbda136f57676a34eea67aba266e5c\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForMaskedLM.\n",
      "\n",
      "All the weights of DistilBertForMaskedLM were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "original_model_outputs = [test_model(model, x) for x in testing_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2dee10f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Nike review training dataset\n",
    "nike_attrs = {\n",
    "    \"version\": \"0.1.0\",\n",
    "    'source': \"nike review dataset\",\n",
    "    'url': 'https://www.kaggle.com/datasets/tinkuzp23/nike-onlinestore-customer-reviews?resource=download',\n",
    "}\n",
    "# Download the dataset from the url, zip it and copy the csv file here\n",
    "nike_reviews_dataset1 = create_dataset_from_csv(\"web_scraped.csv\", \"Content\", \"nike_reviews_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf52e6a-0f3c-447d-903d-101b7392c44a",
   "metadata": {},
   "source": [
    "Let's use Nike onlinestore customer reviews from Kaggle and filter data using UpTrain signals to retrain our model upon. Please download the data from the [link](https://www.kaggle.com/datasets/tinkuzp23/nike-onlinestore-customer-reviews?resource=download) and unzip it here.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d9edc5da-8366-4c55-93a7-4601c89c9970",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the folder:  uptrain_smart_data\n"
     ]
    }
   ],
   "source": [
    "def nike_positive_sentiment_func(inputs, outputs, gts=None, extra_args={}):\n",
    "    is_positives = []\n",
    "    for input in inputs[\"text\"]:\n",
    "        txt = input.lower()\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        score = sia.polarity_scores(txt)\n",
    "\n",
    "        is_negative = score['pos'] < 0.25\n",
    "        for neg_adj in ['expensive', 'worn', 'cheap', 'inexpensive', 'dirty', 'bad' , 'worst' , 'incomplete' , 'defunct' , 'not satisfactory' , ]:\n",
    "            if neg_adj in txt:\n",
    "                is_negative = True\n",
    "\n",
    "        is_positives.append(bool(1-is_negative))\n",
    "    return is_positives\n",
    "\n",
    "cfg = {\n",
    "    'checks': [{\n",
    "        'type': uptrain.Anomaly.EDGE_CASE,\n",
    "        \"signal_formulae\": uptrain.Signal(\"Nike Positive Sentiment\", nike_positive_sentiment_func)\n",
    "    }],\n",
    "\n",
    "    # Define where to save the retraining dataset\n",
    "    'retraining_folder': \"uptrain_smart_data\",\n",
    "    \n",
    "    # Define when to retrain, define a large number because we are using UpTrain just to create retraining dataset\n",
    "    'retrain_after': 10000000000\n",
    "}\n",
    "\n",
    "framework = uptrain.Framework(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "abe66970-c0ce-421d-9f7a-845453615903",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50  edge cases identified out of  135  total samples\n"
     ]
    }
   ],
   "source": [
    "with open(nike_reviews_dataset1) as f:\n",
    "    all_data = json.load(f)\n",
    "\n",
    "for sample in all_data['data']:\n",
    "    inputs = {'data': {'text': [sample['text']]}}\n",
    "    framework.log(inputs = inputs, outputs = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ee055a02-66a4-498f-b9e0-563c60d53fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples filtered for retraining:  82\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples filtered for retraining: \", len(pd.read_csv(\"uptrain_smart_data/1/smart_data.csv\")))\n",
    "retraining_dataset = create_dataset_from_csv(\"uptrain_smart_data/1/smart_data.csv\", \"text\", \"retrain_dataset.json\", min_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca8d91d9-4540-4850-ad27-69fe9468e7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-8e3ab05d96f393bb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to C:/Users/KANCHAN KUMAR KAITY/.cache/huggingface/datasets/json/default-8e3ab05d96f393bb/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3466b6f824d6441ba86cdf9f23f71bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6aa1c6b7bef467590979987efc2d63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e077454449c4696816686d3f756a3e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to C:/Users/KANCHAN KUMAR KAITY/.cache/huggingface/datasets/json/default-8e3ab05d96f393bb/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3fec3b749214fd68ffced922b9cfdee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab45463bef234975ac7e5621c75b2a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a6d37ce4264f6d98ba041cb9334e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c27fb105994905a4e919d35beb97b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "c:\\Users\\KANCHAN KUMAR KAITY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 204\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n",
      "  Number of trainable parameters = 66985530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>Before training, Perplexity: 27.42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0f55fb527743958c1c058c969bd8f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2acac8b6624ad6af1a9afa1da436e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.236717462539673, 'eval_runtime': 3.7296, 'eval_samples_per_second': 6.167, 'eval_steps_per_second': 0.268, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf4bcf6869e491f855f64d3ed628d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.964031934738159, 'eval_runtime': 4.9192, 'eval_samples_per_second': 4.676, 'eval_steps_per_second': 0.203, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7686b39f4d7c45c0b75366f806335286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0635790824890137, 'eval_runtime': 5.7526, 'eval_samples_per_second': 3.998, 'eval_steps_per_second': 0.174, 'epoch': 3.0}\n",
      "{'train_runtime': 529.1098, 'train_samples_per_second': 1.157, 'train_steps_per_second': 0.023, 'train_loss': 3.102147420247396, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435fe6abbae747988df944302fc60250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>After training, Perplexity: 25.08\n"
     ]
    }
   ],
   "source": [
    "retrain_model(model, retraining_dataset)\n",
    "retrained_model_outputs = [test_model(model, x) for x in testing_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f014895c-0e6d-4886-a9b4-7071154e6315",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['popular', 'expensive', 'durable', 'common', 'comfortable'],\n",
       "  ['closed', 'defunct', 'open', 'incomplete', 'available']],\n",
       " [['popular', 'expensive', 'comfortable', 'durable', 'good'],\n",
       "  ['defunct', 'closed', 'available', 'open', 'incomplete']]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[original_model_outputs, retrained_model_outputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8114dbc6",
   "metadata": {},
   "source": [
    "For second dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ec52141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Nike review training dataset\n",
    "nike_attrs = {\n",
    "    \"version\": \"0.1.0\",\n",
    "    'source': \"nike_feedback\",\n",
    "    'url': 'kaggle kernels output asjad2024/distilbert-based-uncased-fine-tuning-on-custom -p /path/to/dest',\n",
    "}\n",
    "# Download the dataset from the url, zip it and copy the csv file here\n",
    "nike_reviews_dataset2 = create_dataset_from_csv(\"nike_2020_04_13.csv\", \"Description\", \"nike_reviews_data2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8c259369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the folder:  uptrain_smart_data2\n"
     ]
    }
   ],
   "source": [
    "def nike_positive_sentiment_func(inputs, outputs, gts=None, extra_args={}):\n",
    "    is_positives = []\n",
    "    for input in inputs[\"text\"]:\n",
    "        txt = input.lower()\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        score = sia.polarity_scores(txt)\n",
    "\n",
    "        is_negative = score['pos'] < 0.25\n",
    "        for neg_adj in ['expensive', 'worn', 'cheap', 'inexpensive', 'dirty', 'bad' , 'worst']:\n",
    "            if neg_adj in txt:\n",
    "                is_negative = True\n",
    "\n",
    "        is_positives.append(bool(1-is_negative))\n",
    "    return is_positives\n",
    "\n",
    "cfg = {\n",
    "    'checks': [{\n",
    "        'type': uptrain.Anomaly.EDGE_CASE,\n",
    "        \"signal_formulae\": uptrain.Signal(\"Nike Positive Sentiment\", nike_positive_sentiment_func)\n",
    "    }],\n",
    "\n",
    "    # Define where to save the retraining dataset\n",
    "    'retraining_folder': \"uptrain_smart_data2\",\n",
    "    \n",
    "    # Define when to retrain, define a large number because we are using UpTrain just to create retraining dataset\n",
    "    'retrain_after': 10000000000\n",
    "}\n",
    "\n",
    "framework = uptrain.Framework(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cab13e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50  edge cases identified out of  348  total samples\n"
     ]
    }
   ],
   "source": [
    "with open(nike_reviews_dataset2) as f:\n",
    "    all_data = json.load(f)\n",
    "\n",
    "for sample in all_data['data']:\n",
    "    inputs = {'data': {'text': [sample['text']]}}\n",
    "    framework.log(inputs = inputs, outputs = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b4588eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples filtered for retraining:  82\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples filtered for retraining: \", len(pd.read_csv(\"uptrain_smart_data2/1/smart_data.csv\")))\n",
    "retraining_dataset2 = create_dataset_from_csv(\"uptrain_smart_data2/1/smart_data.csv\", \"text\", \"retrain_dataset2.json\", min_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de3b8802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-0d9ecc2fe1ff932e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to C:/Users/KANCHAN KUMAR KAITY/.cache/huggingface/datasets/json/default-0d9ecc2fe1ff932e/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1a144f1a08420f8c77b6942c8edd69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5efd688c07cf45f0a6d60038b3cfc268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5580c0ed15fc4bfba82bc43390815835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to C:/Users/KANCHAN KUMAR KAITY/.cache/huggingface/datasets/json/default-0d9ecc2fe1ff932e/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00feeb08250b4531bfe0df49dc35313d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5ec421362c4363a9c39accbbce13e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110d86942a694350a46366d9b1d044ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef13f984d8e4d559e80aa0531db0ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 455\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n",
      "  Number of trainable parameters = 66985530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>Before training, Perplexity: 39.71\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba37b2198e1c49efa3a01504e1e81706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122aa1969dbc4b4db3b0ef9f5a13770b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2097129821777344, 'eval_runtime': 10.0262, 'eval_samples_per_second': 5.087, 'eval_steps_per_second': 0.1, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4985a3fdb64f68ada1cfcc0c0f0480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.063210964202881, 'eval_runtime': 8.4339, 'eval_samples_per_second': 6.047, 'eval_steps_per_second': 0.119, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb215248a404905b73b85d38e02f8b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7324538230895996, 'eval_runtime': 10.1552, 'eval_samples_per_second': 5.022, 'eval_steps_per_second': 0.098, 'epoch': 3.0}\n",
      "{'train_runtime': 1297.9011, 'train_samples_per_second': 1.052, 'train_steps_per_second': 0.018, 'train_loss': 3.3099263509114585, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69fb373fcebc4272a55609d086cda31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>After training, Perplexity: 20.74\n"
     ]
    }
   ],
   "source": [
    "retrain_model(model, retraining_dataset2)\n",
    "retrained_model_outputs2 = [test_model(model, x) for x in testing_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3eafe9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['popular', 'expensive', 'durable', 'common', 'comfortable'],\n",
       "  ['closed', 'defunct', 'open', 'incomplete', 'available']],\n",
       " [['popular', 'comfortable', 'durable', 'expensive', 'versatile'],\n",
       "  ['free', 'open', 'available', 'defunct', 'closed']]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[original_model_outputs, retrained_model_outputs2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c9f097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_word_func(inputs, outputs, gts=None, extra_args={}):\n",
    "    is_positives = []\n",
    "    for input in inputs[\"text\"]:\n",
    "        txt = input.lower()\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        score = sia.polarity_scores(txt)\n",
    "\n",
    "        is_negative = score['pos'] < 0.25\n",
    "        for neg_adj in ['Adidas','Burberry','Gucci','Jimmy','Salvatore Ferragamo','Bugatti',\n",
    "                       'Airwalk','Lacoste','Lee Cooper','Red Tape','Fila','Balenciaga','Puma',\n",
    "                       'Levis','Tommy Hilfiger','Jordan','Reebok','Woodland',\n",
    "                       'Sparx','Red Chief','Diesel','Calvin Klein','US Polo']:\n",
    "            if neg_adj in txt:\n",
    "                is_negative = True\n",
    "\n",
    "        is_positives.append(bool(1-is_negative))\n",
    "    return is_positives\n",
    "\n",
    "cfg = {\n",
    "    'checks': [{\n",
    "        'type': uptrain.Anomaly.EDGE_CASE,\n",
    "        \"signal_formulae\": uptrain.Signal(\"Nike word remove\", remove_word_func)\n",
    "    }],\n",
    "\n",
    "    # Define where to save the retraining dataset\n",
    "    'retraining_folder': \"uptrain_smart_data3\",\n",
    "    \n",
    "    # Define when to retrain, define a large number because we are using UpTrain just to create retraining dataset\n",
    "    'retrain_after': 10000000000\n",
    "}\n",
    "\n",
    "framework = uptrain.Framework(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3b00ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(nike_reviews_dataset2) as f:\n",
    "    all_data = json.load(f)\n",
    "\n",
    "for sample in all_data['data']:\n",
    "    inputs = {'data': {'text': [sample['text']]}}\n",
    "    framework.log(inputs = inputs, outputs = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f941e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of samples filtered for retraining: \", len(pd.read_csv(\"uptrain_smart_data3/1/smart_data.csv\")))\n",
    "retraining_dataset3 = create_dataset_from_csv(\"uptrain_smart_data3/1/smart_data.csv\", \"text\", \"retrain_dataset3.json\", min_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a9e0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain_model(model, retraining_dataset3)\n",
    "retrained_model_outputs3 = [test_model(model, x) for x in testing_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245a90f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "[original_model_outputs, retrained_model_outputs3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "11fd87750f518b4cfe968f4a4981081e57e3acd89fbd723b40467759e0b63354"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
